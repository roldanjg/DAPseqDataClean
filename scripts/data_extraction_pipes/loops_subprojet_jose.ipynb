{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4afeb9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "results_folder_path = '/home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks'\n",
    "experiments_dic = {}\n",
    "input_narrowpeaks_folders = ['data_loops_fl_1','data_loops_fl_2']\n",
    "input_narrowpeaks_subfolders = ['MYC2FL/loopPIF4','MYC2FL/loopPIF5','MYC2FL/WT']\n",
    "\n",
    "# parse the experiments file to get the id of each exeriment and the path to that experiment\n",
    "for experiment in input_narrowpeaks_subfolders:\n",
    "    experiments_dic[experiment] = []\n",
    "    \n",
    "    for parent_folder in input_narrowpeaks_folders:\n",
    "        path = os.path.join(basePathDataFolder,parent_folder,experiment)\n",
    "        filesInFolder = os.listdir(path)\n",
    "    \n",
    "        narrowpeakFileOriginalPath = os.path.join(\n",
    "            path,'GEMout','GEMout.GEM_events.narrowPeak'\n",
    "        )\n",
    "        narrowpeakFileDestinationPath = os.path.join(\n",
    "        results_folder_path,experiment.replace('/','_')+'_replicate'+parent_folder[-1]+'.narrowPeak'\n",
    "            )\n",
    "        experiments_dic[experiment].append(narrowpeakFileDestinationPath)\n",
    "        #shutil.copy(narrowpeakFileOriginalPath,narrowpeakFileDestinationPath)\n",
    "        #print(narrowpeakFileOriginalPath,narrowpeakFileDestinationPath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3fecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedtools intersect -wb -wa -a /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_loopPIF4_replicate1.narrowPeak -b /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_loopPIF4_replicate2.narrowPeak -f 0.9 -r\n",
      "19690\n",
      "bedtools intersect -wb -wa -a /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_loopPIF5_replicate1.narrowPeak -b /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_loopPIF5_replicate2.narrowPeak -f 0.9 -r\n",
      "13297\n",
      "bedtools intersect -wb -wa -a /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_WT_replicate1.narrowPeak -b /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_WT_replicate2.narrowPeak -f 0.9 -r\n",
      "7576\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "results_folder_path = '/home/joaquin/projects/methylation/data/loops_subproject_jose/allDataNarrowPeaksmin2repNineCoincidence'\n",
    "Path(results_folder_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for experiment in input_narrowpeaks_subfolders:\n",
    "    commonPeaksthreeReplicates = set()\n",
    "    statement = 'bedtools intersect -wb -wa -a {} -b {} -f 0.9 -r'.format(\n",
    "            experiments_dic[experiment][0],experiments_dic[experiment][1]\n",
    "        )\n",
    "    print(statement)\n",
    "    endProcess = subprocess.run(\n",
    "        statement,\n",
    "        shell=True,\n",
    "        capture_output=True\n",
    "    )\n",
    "        # first check if the subcommand has the standar err empty, whith mean it has run correct.\n",
    "    if endProcess.stderr.decode('ascii') == '':\n",
    "        # if it is correct then split the lines in two parts(the firs and second file matchs) and finally split\n",
    "        # in individual coordinates\n",
    "        # lastly generate a set, this way only will save non repeated values \n",
    "\n",
    "        stdoutLines = endProcess.stdout.decode('UTF-8').replace('\\tchr', '\\nchr').split('\\n')[:-1]\n",
    "        for line in stdoutLines:\n",
    "            commonPeaksthreeReplicates.add(line)\n",
    "    else:\n",
    "        print('there is an error related with bedtools')\n",
    "\n",
    "    narrowpeakFileDestinationPath = os.path.join(\n",
    "            results_folder_path,experiment.replace('/','_')+'_replicates_common_Peaks_2_reps.narrowPeak'\n",
    "        )\n",
    "    print(len(commonPeaksthreeReplicates))\n",
    "    with open(narrowpeakFileDestinationPath,'w') as mergePeaksFile:\n",
    "\n",
    "        for line in commonPeaksthreeReplicates:\n",
    "            mergePeaksFile.write(line+'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "883188cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedtools intersect -wb -wa -a /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_loopPIF4_replicate1.narrowPeak -b /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_loopPIF4_replicate2.narrowPeak -f 0.6 -r\n",
      "23635\n",
      "bedtools intersect -wb -wa -a /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_loopPIF5_replicate1.narrowPeak -b /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_loopPIF5_replicate2.narrowPeak -f 0.6 -r\n",
      "18265\n",
      "bedtools intersect -wb -wa -a /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_WT_replicate1.narrowPeak -b /home/joaquin/projects/methylation/data/loops_subproject_jose/allNarrowpeaks/MYC2FL_WT_replicate2.narrowPeak -f 0.6 -r\n",
      "11509\n"
     ]
    }
   ],
   "source": [
    "d\n",
    "results_folder_path = '/home/joaquin/projects/methylation/data/loops_subproject_jose/allDataNarrowPeaksmin2repSixCoincidence'\n",
    "Path(results_folder_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for experiment in input_narrowpeaks_subfolders:\n",
    "    commonPeaksthreeReplicates = set()\n",
    "    statement = 'bedtools intersect -wb -wa -a {} -b {} -f 0.6 -r'.format(\n",
    "            experiments_dic[experiment][0],experiments_dic[experiment][1]\n",
    "        )\n",
    "    print(statement)\n",
    "    endProcess = subprocess.run(\n",
    "        statement,\n",
    "        shell=True,\n",
    "        capture_output=True\n",
    "    )\n",
    "        # first check if the subcommand has the standar err empty, whith mean it has run correct.\n",
    "    if endProcess.stderr.decode('ascii') == '':\n",
    "        # if it is correct then split the lines in two parts(the firs and second file matchs) and finally split\n",
    "        # in individual coordinates\n",
    "        # lastly generate a set, this way only will save non repeated values \n",
    "\n",
    "        stdoutLines = endProcess.stdout.decode('UTF-8').replace('\\tchr', '\\nchr').split('\\n')[:-1]\n",
    "        for line in stdoutLines:\n",
    "            commonPeaksthreeReplicates.add(line)\n",
    "    else:\n",
    "        print('there is an error related with bedtools')\n",
    "\n",
    "    narrowpeakFileDestinationPath = os.path.join(\n",
    "            results_folder_path,experiment.replace('/','_')+'_replicates_common_Peaks_2_reps.narrowPeak'\n",
    "        )\n",
    "    print(len(commonPeaksthreeReplicates))\n",
    "    with open(narrowpeakFileDestinationPath,'w') as mergePeaksFile:\n",
    "\n",
    "        for line in commonPeaksthreeReplicates:\n",
    "            mergePeaksFile.write(line+'\\n')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68653e40",
   "metadata": {},
   "source": [
    "yo no he hecho este paso ahora porque he aplicado el sort a la lista de despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc850e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "basePathDataFolder = '/home/joaquin/projects/methylation/data'\n",
    "dataFolder = 'allDataNarrowPeaksmin2repSixCoincidence'\n",
    "folderPath = os.path.join(\n",
    "                basePathDataFolder,dataFolder\n",
    "            )\n",
    "listOfFiles = glob.glob(folderPath+'/*')\n",
    "for fileName in listOfFiles:\n",
    "    print(fileName)\n",
    "    endProcess = subprocess.run(\n",
    "        \"sort -k 1.4n,1n -k2,2n {} > temp1 && cat temp1 > {} && rm temp1\".format(fileName,fileName),\n",
    "        shell=True,\n",
    "        capture_output=True)\n",
    "    print(endProcess.stderr)\n",
    "    if endProcess.stderr.decode('ascii') != '':\n",
    "        print(\"WARNING THERE IS A PROBLEN SORTING: \", endProcess.stderr.decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d03b977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joaquin/projects/methylation/data/loops_subproject_jose/allDataNarrowPeaksmin2repNineCoincidence/MYC2FL_loopPIF4_replicates_common_Peaks_2_reps.narrowPeak\n",
      "9920\n",
      "/home/joaquin/projects/methylation/data/loops_subproject_jose/allDataNarrowPeaksmin2repNineCoincidence/MYC2FL_loopPIF5_replicates_common_Peaks_2_reps.narrowPeak\n",
      "6741\n",
      "/home/joaquin/projects/methylation/data/loops_subproject_jose/allDataNarrowPeaksmin2repNineCoincidence/MYC2FL_WT_replicates_common_Peaks_2_reps.narrowPeak\n",
      "3834\n"
     ]
    }
   ],
   "source": [
    "# TODO extract the common sequence of the regulation in each fragment.\n",
    "#https://stackoverflow.com/questions/10016802/grouping-a-list-of-integers-with-nearest-values\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from statistics import mean\n",
    "basePathDataFolder = '/home/joaquin/projects/methylation/data/loops_subproject_jose/'\n",
    "dataFolder = 'allDataNarrowPeaksmin2repNineCoincidence'\n",
    "dataFolderDestination = 'allDataNarrowPeaksmin2repNineCoincidenceSingleSequence'\n",
    "dataFolderDestination_path = os.path.join(\n",
    "                basePathDataFolder,dataFolderDestination,\n",
    "            )\n",
    "Path(dataFolderDestination_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "spaceValue = 20\n",
    "folderPath = os.path.join(\n",
    "                basePathDataFolder,dataFolder\n",
    "            )\n",
    "listOfFiles = glob.glob(folderPath+'/*')\n",
    "\n",
    "def saveFile(dictOfCommonNPEvents, destinationFilePath):\n",
    "    count = 0\n",
    "    with open(destinationFilePath, 'a+') as destFile:\n",
    "        for chrm in dictOfCommonNPEvents:\n",
    "            for coordinates in dictOfCommonNPEvents[chrm]:\n",
    "                count +=1\n",
    "                \n",
    "                destFile.write('chr{}\\t{}\\t{}\\t{}:{}\\n'.format(chrm,coordinates[0],coordinates[1],chrm,coordinates[2]))\n",
    "    print(count)\n",
    "for fileName in listOfFiles:\n",
    "    dictOfCommonNPEvents = {}\n",
    "    \n",
    "    destinationFilePath = os.path.join(\n",
    "                basePathDataFolder,dataFolderDestination, fileName.split('/')[-1]\n",
    "            )\n",
    "    #Just keep the 3erd col that contains the center coordinate and the chr, split : to separate\n",
    "    #chr:coordinate, and generate a list to work with\n",
    "    print(fileName)\n",
    "    with open(fileName, 'r') as NPEvents:\n",
    "        for line in NPEvents:\n",
    "            chrAndCoor = list(map(lambda x: int(x), line.strip().split('\\t')[3].split(':')))\n",
    "            dictOfCommonNPEvents.setdefault(chrAndCoor[0], [])\n",
    "            dictOfCommonNPEvents[chrAndCoor[0]].append(chrAndCoor[1])\n",
    "    for chrm in dictOfCommonNPEvents:\n",
    "        sortEachChr = sorted(dictOfCommonNPEvents[chrm])\n",
    "        dictOfCommonNPEvents[chrm] = sortEachChr\n",
    "\n",
    "        m = [[dictOfCommonNPEvents[chrm][0]]]\n",
    "        \n",
    "        for x in dictOfCommonNPEvents[chrm][1:]:\n",
    "\n",
    "                if x - m[-1][-1] < spaceValue:\n",
    "                    m[-1].append(x)\n",
    "                else:\n",
    "                    meanValPeak = int(mean(m[-1]))\n",
    "                    m.pop()\n",
    "                    m.append([meanValPeak-100,meanValPeak+101, meanValPeak])\n",
    "                    m.append([x])\n",
    "\n",
    "        meanValPeak = int(mean(m[-1]))\n",
    "        m.pop()\n",
    "        m.append([meanValPeak-100,meanValPeak+101, meanValPeak])\n",
    "        dictOfCommonNPEvents[chrm] = m\n",
    "    \n",
    "    saveFile(dictOfCommonNPEvents, destinationFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee1068e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joaquin/projects/methylation/data/loops_subproject_jose/allDataNarrowPeaksmin2repSixCoincidence/MYC2FL_loopPIF4_replicates_common_Peaks_2_reps.narrowPeak\n",
      "13865\n",
      "/home/joaquin/projects/methylation/data/loops_subproject_jose/allDataNarrowPeaksmin2repSixCoincidence/MYC2FL_loopPIF5_replicates_common_Peaks_2_reps.narrowPeak\n",
      "11709\n",
      "/home/joaquin/projects/methylation/data/loops_subproject_jose/allDataNarrowPeaksmin2repSixCoincidence/MYC2FL_WT_replicates_common_Peaks_2_reps.narrowPeak\n",
      "7767\n"
     ]
    }
   ],
   "source": [
    "# TODO extract the common sequence of the regulation in each fragment.\n",
    "#https://stackoverflow.com/questions/10016802/grouping-a-list-of-integers-with-nearest-values\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from statistics import mean\n",
    "basePathDataFolder = '/home/joaquin/projects/methylation/data/loops_subproject_jose/'\n",
    "dataFolder = 'allDataNarrowPeaksmin2repSixCoincidence'\n",
    "dataFolderDestination = 'allDataNarrowPeaksmin2repSixCoincidenceSingleSequence'\n",
    "dataFolderDestination_path = os.path.join(\n",
    "                basePathDataFolder,dataFolderDestination,\n",
    "            )\n",
    "Path(dataFolderDestination_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "spaceValue = 20\n",
    "folderPath = os.path.join(\n",
    "                basePathDataFolder,dataFolder\n",
    "            )\n",
    "listOfFiles = glob.glob(folderPath+'/*')\n",
    "\n",
    "def saveFile(dictOfCommonNPEvents, destinationFilePath):\n",
    "    count = 0\n",
    "    with open(destinationFilePath, 'a+') as destFile:\n",
    "        for chrm in dictOfCommonNPEvents:\n",
    "            for coordinates in dictOfCommonNPEvents[chrm]:\n",
    "                count +=1\n",
    "                \n",
    "                destFile.write('chr{}\\t{}\\t{}\\t{}:{}\\n'.format(chrm,coordinates[0],coordinates[1],chrm,coordinates[2]))\n",
    "    print(count)\n",
    "for fileName in listOfFiles:\n",
    "    dictOfCommonNPEvents = {}\n",
    "    \n",
    "    destinationFilePath = os.path.join(\n",
    "                basePathDataFolder,dataFolderDestination, fileName.split('/')[-1]\n",
    "            )\n",
    "    #Just keep the 3erd col that contains the center coordinate and the chr, split : to separate\n",
    "    #chr:coordinate, and generate a list to work with\n",
    "    print(fileName)\n",
    "    with open(fileName, 'r') as NPEvents:\n",
    "        for line in NPEvents:\n",
    "            chrAndCoor = list(map(lambda x: int(x), line.strip().split('\\t')[3].split(':')))\n",
    "            dictOfCommonNPEvents.setdefault(chrAndCoor[0], [])\n",
    "            dictOfCommonNPEvents[chrAndCoor[0]].append(chrAndCoor[1])\n",
    "    for chrm in [1,2,3,4,5]:\n",
    "        sortEachChr = sorted(dictOfCommonNPEvents[chrm])\n",
    "        dictOfCommonNPEvents[chrm] = sortEachChr\n",
    "        m = [[dictOfCommonNPEvents[chrm][0]]]\n",
    "        \n",
    "        for x in dictOfCommonNPEvents[chrm][1:]:\n",
    "\n",
    "                if x - m[-1][-1] < spaceValue:\n",
    "                    m[-1].append(x)\n",
    "                else:\n",
    "                    meanValPeak = int(mean(m[-1]))\n",
    "                    m.pop()\n",
    "                    m.append([meanValPeak-100,meanValPeak+101, meanValPeak])\n",
    "                    m.append([x])\n",
    "\n",
    "        meanValPeak = int(mean(m[-1]))\n",
    "        m.pop()\n",
    "        m.append([meanValPeak-100,meanValPeak+101, meanValPeak])\n",
    "        dictOfCommonNPEvents[chrm] = m\n",
    "    \n",
    "    saveFile(dictOfCommonNPEvents, destinationFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c657669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102164, 117784, 131488, 144724, 144725, 144937, 144938, 151228, 158300, 158300, 161924, 163610, 163701, 170705, 178973, 178974, 183471, 183472, 188778, 188779]\n",
      "[21202, 43353, 66594, 78050, 81301, 81302, 81302, 131708, 131709, 131728, 131729, 131729, 132197, 132197, 157408, 159558, 161824, 161829, 162078, 162085]\n",
      "[4289, 9464, 9464, 9484, 16388, 22149, 22157, 26146, 26256, 26257, 27021, 27021, 27737, 27737, 31941, 31944, 57761, 57762, 76502, 76503]\n",
      "[1536, 1539, 1540, 12018, 12018, 14748, 14748, 14749, 15522, 15523, 21684, 37946, 37947, 41966, 41967, 51843, 51847, 59910, 99403, 99443]\n",
      "[6347, 6351, 6541, 11013, 13401, 13407, 18902, 32654, 32654, 32829, 40533, 40534, 40534, 44558, 44565, 56381, 56382, 60926, 62431, 75889]\n",
      "13701\n"
     ]
    }
   ],
   "source": [
    "# TODO extract the common sequence of the regulation in each fragment.\n",
    "#https://stackoverflow.com/questions/10016802/grouping-a-list-of-integers-with-nearest-values\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from statistics import mean\n",
    "basePathDataFolder = '/home/joaquin/projects/methylation/data/loops_subproject_jose'\n",
    "dataFolder = 'allDataNarrowPeaksmin2repNineCoincidenceSingleSequence'\n",
    "dataFolderDestination = 'allDataNarrowPeaksmin2repNineCoincidenceSingleSequence'\n",
    "spaceValue = 20\n",
    "folderPath = os.path.join(\n",
    "                basePathDataFolder,dataFolder\n",
    "            )\n",
    "listOfFiles = glob.glob(folderPath+'/*')\n",
    "dictOfCommonNPEvents = {}\n",
    "destinationFilePath = os.path.join(\n",
    "                basePathDataFolder,dataFolderDestination + '_alltheposiblepeaks20correct.bed'\n",
    "            )\n",
    "\n",
    "\n",
    "def saveFile(dictOfCommonNPEvents, destinationFilePath):\n",
    "    counter = 0\n",
    "    with open(destinationFilePath, 'a+') as destFile:\n",
    "        for chrm in [1,2,3,4,5]:\n",
    "            for coordinates in dictOfCommonNPEvents[chrm]:\n",
    "                counter +=1\n",
    "                destFile.write('chr{}\\t{}\\t{}\\t{}:{}\\n'.format(chrm,coordinates[0],coordinates[1],chrm,coordinates[2]))\n",
    "    print(counter)\n",
    "\n",
    "for fileName in listOfFiles:\n",
    "    #Just keep the 3erd col that contains the center coordinate and the chr, split : to separate\n",
    "    #chr:coordinate, and generate a list to work with\n",
    "\n",
    "    with open(fileName, 'r') as NPEvents:\n",
    "        for line in NPEvents:\n",
    "            chrAndCoor = list(map(lambda x: int(x), line.strip().split('\\t')[3].split(':')))\n",
    "            dictOfCommonNPEvents.setdefault(chrAndCoor[0], [])\n",
    "            dictOfCommonNPEvents[chrAndCoor[0]].append(chrAndCoor[1])\n",
    "\n",
    "for chrm in dictOfCommonNPEvents:\n",
    "#     print(dictOfCommonNPEvents[chrm])\n",
    "#     print(dictOfCommonNPEvents[chrm][0:20])\n",
    "    sortEachChr = sorted(dictOfCommonNPEvents[chrm])\n",
    "    dictOfCommonNPEvents[chrm] = sortEachChr\n",
    "    print(dictOfCommonNPEvents[chrm][0:20])\n",
    "    m = [[dictOfCommonNPEvents[chrm][0]]]\n",
    "\n",
    "    for x in dictOfCommonNPEvents[chrm][1:]:\n",
    "\n",
    "            if x - m[-1][-1] < spaceValue:\n",
    "                m[-1].append(x)\n",
    "            else:\n",
    "                meanValPeak = int(mean(m[-1]))\n",
    "                m.pop()\n",
    "                m.append([meanValPeak-100,meanValPeak+101, meanValPeak])\n",
    "                m.append([x])\n",
    "\n",
    "    meanValPeak = int(mean(m[-1]))\n",
    "    m.pop()\n",
    "    m.append([meanValPeak-100,meanValPeak+101, meanValPeak])\n",
    "    dictOfCommonNPEvents[chrm] = m\n",
    "\n",
    "saveFile(dictOfCommonNPEvents, destinationFilePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ea0ef8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23147\n"
     ]
    }
   ],
   "source": [
    "# TODO extract the common sequence of the regulation in each fragment.\n",
    "#https://stackoverflow.com/questions/10016802/grouping-a-list-of-integers-with-nearest-values\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from statistics import mean\n",
    "basePathDataFolder = '/home/joaquin/projects/methylation/data/loops_subproject_jose'\n",
    "dataFolder = 'allDataNarrowPeaksmin2repSixCoincidenceSingleSequence'\n",
    "dataFolderDestination = 'allDataNarrowPeaksmin2repSixCoincidenceSingleSequence'\n",
    "spaceValue = 20\n",
    "folderPath = os.path.join(\n",
    "                basePathDataFolder,dataFolder\n",
    "            )\n",
    "listOfFiles = glob.glob(folderPath+'/*')\n",
    "dictOfCommonNPEvents = {}\n",
    "destinationFilePath = os.path.join(\n",
    "                basePathDataFolder,dataFolderDestination + '_alltheposiblepeaks20correct.bed'\n",
    "            )\n",
    "\n",
    "\n",
    "def saveFile(dictOfCommonNPEvents, destinationFilePath):\n",
    "    counter = 0\n",
    "    with open(destinationFilePath, 'a+') as destFile:\n",
    "        for chrm in [1,2,3,4,5]:\n",
    "            for coordinates in dictOfCommonNPEvents[chrm]:\n",
    "                counter +=1\n",
    "                destFile.write('chr{}\\t{}\\t{}\\t{}:{}\\n'.format(chrm,coordinates[0],coordinates[1],chrm,coordinates[2]))\n",
    "    print(counter)\n",
    "\n",
    "for fileName in listOfFiles:\n",
    "    #Just keep the 3erd col that contains the center coordinate and the chr, split : to separate\n",
    "    #chr:coordinate, and generate a list to work with\n",
    "\n",
    "    with open(fileName, 'r') as NPEvents:\n",
    "        for line in NPEvents:\n",
    "            chrAndCoor = list(map(lambda x: int(x), line.strip().split('\\t')[3].split(':')))\n",
    "            dictOfCommonNPEvents.setdefault(chrAndCoor[0], [])\n",
    "            dictOfCommonNPEvents[chrAndCoor[0]].append(chrAndCoor[1])\n",
    "\n",
    "for chrm in dictOfCommonNPEvents:\n",
    "#     print(dictOfCommonNPEvents[chrm])\n",
    "#     print(dictOfCommonNPEvents[chrm][0:20])\n",
    "    sortEachChr = sorted(dictOfCommonNPEvents[chrm])\n",
    "    dictOfCommonNPEvents[chrm] = sortEachChr\n",
    "    # print(dictOfCommonNPEvents[chrm][0:20])\n",
    "    m = [[dictOfCommonNPEvents[chrm][0]]]\n",
    "\n",
    "    for x in dictOfCommonNPEvents[chrm][1:]:\n",
    "\n",
    "            if x - m[-1][-1] < spaceValue:\n",
    "                m[-1].append(x)\n",
    "            else:\n",
    "                meanValPeak = int(mean(m[-1]))\n",
    "                m.pop()\n",
    "                m.append([meanValPeak-100,meanValPeak+101, meanValPeak])\n",
    "                m.append([x])\n",
    "\n",
    "    meanValPeak = int(mean(m[-1]))\n",
    "    m.pop()\n",
    "    m.append([meanValPeak-100,meanValPeak+101, meanValPeak])\n",
    "    dictOfCommonNPEvents[chrm] = m\n",
    "\n",
    "saveFile(dictOfCommonNPEvents, destinationFilePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3faee926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import tempfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# reduce new function https://stackoverflow.com/questions/44327999/python-pandas-merge-multiple-dataframes\n",
    "\n",
    "commonpeaksfile = '/home/joaquin/projects/methylation/data/loops_subproject_jose/allDataNarrowPeaksmin2repNineCoincidenceSingleSequence_alltheposiblepeaks20correct.bed'\n",
    "\n",
    "basePathDataFolder = '/home/joaquin/projects/methylation/data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2f3dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performIntersect(folder, intersectFile):\n",
    "    \n",
    "    sortedBamFile = glob.glob(f'{folder}/*orted.bam')\n",
    "    \n",
    "    if len(sortedBamFile) != 1:\n",
    "        return print(folder, ' has a problem selecting File')\n",
    "    else:\n",
    "        sortedBamFile = sortedBamFile[0]\n",
    "    \n",
    "    outputFile = intersectFile.strip().split('/')[-1][:-4]+'_'+sortedBamFile.split('/')[-1][:-10]+'.bed'\n",
    "    outputFilePath = os.path.join(folder,outputFile)\n",
    "\n",
    "\n",
    "    print(outputFilePath)\n",
    "    \n",
    "    if os.path.isfile(outputFilePath):\n",
    "        os.remove(outputFilePath)\n",
    "    if not os.path.isfile(outputFilePath):\n",
    "        subprocess.call(\n",
    "            'samtools' + ' view -q1 -b ' + sortedBamFile + ' | ' +\n",
    "            'bedtools' + ' intersect -abam stdin -b ' + intersectFile + ' -bed -wb -f 0.5 ' +\n",
    "            '> ' + outputFilePath , shell=True\n",
    "        )\n",
    "    else:\n",
    "        print(outputFile, ' is already done')\n",
    "    \n",
    "    totalForBox = {}\n",
    "    with open(outputFilePath, 'r') as intersectOut:\n",
    "        intersectDf = pd.read_csv(\n",
    "            intersectOut, sep='\\t', usecols=[3, 12, 13, 14, 15],\n",
    "            names=['intersected', 'chr', 'start', 'end', 'boxname'],\n",
    "        )\n",
    "        for index, ip in intersectDf.iterrows():\n",
    "            intersectOcurrence = str(ip.intersected.split('/')[0])\n",
    "            box = ','.join([str(ip.chr), str(ip.start), str(ip.end), ip.boxname])\n",
    "            if box in totalForBox:\n",
    "                totalForBox[box].add(intersectOcurrence)\n",
    "            else:\n",
    "                totalForBox[box] = {intersectOcurrence}\n",
    "\n",
    "        for box in totalForBox:\n",
    "            boxlen = len(totalForBox[box])\n",
    "            totalForBox[box] = boxlen\n",
    "\n",
    "        with open(outputFilePath[:-4] + '_boxtotals.csv', 'w') as elcsv:\n",
    "            elcsv.write('chr,start,end,boxname,{}\\n'.format(sortedBamFile.split('/')[-1][:-10]))\n",
    "            for name, recount in totalForBox.items():\n",
    "                elcsv.write('{},{}\\n'.format(name, recount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "794583c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joaquin/projects/methylation/data/data_loops_fl_1/MYC2FL/loopPIF4/allDataNarrowPeaksmin2repNineCoincidenceSingleSequence_alltheposiblepeaks20correct_MYC2FLloopPIF4.bed\n",
      "/home/joaquin/projects/methylation/data/data_loops_fl_2/MYC2FL/loopPIF4/allDataNarrowPeaksmin2repNineCoincidenceSingleSequence_alltheposiblepeaks20correct_MYC2FLloopPIF4.bed\n"
     ]
    }
   ],
   "source": [
    "input_narrowpeaks_folders = ['data_loops_fl_1','data_loops_fl_2']\n",
    "input_narrowpeaks_subfolders = ['MYC2FL/loopPIF4'] #,'MYC2FL/loopPIF5','MYC2FL/WT', 'Input/Input'\n",
    "\n",
    "# parse the experiments file to get the id of each exeriment and the path to that experiment\n",
    "for experiment in input_narrowpeaks_subfolders:\n",
    "    for parent_folder in input_narrowpeaks_folders:\n",
    "        workingFolder = os.path.join(basePathDataFolder,parent_folder,experiment)\n",
    "        performIntersect(workingFolder, commonpeaksfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a91790b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculationBowtieSummary(filepath):\n",
    "    filename = os.path.join(filepath,'bowtie2stats.txt')\n",
    "    with open(filename, 'r') as bowstats:\n",
    "        for line in bowstats:\n",
    "            reads = re.search(r'([\\d]+) reads; of these:',line)\n",
    "            regular = re.search(r'([\\d,\\.]+)% overall alignment rate',line)\n",
    "\n",
    "        return reads.group(1),regular.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40490f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generateDfandNormaliceDataTPMs(folder,dataColName):\n",
    "    csvFile = glob.glob(f'{folder}/allDataNarrowPeaksmin2repNineCoinciden*.csv')\n",
    "    \n",
    "    if len(csvFile) != 1:\n",
    "        return print(folder, ' has a problem selecting File')\n",
    "    else:\n",
    "        csvFilePath = csvFile[0]\n",
    "\n",
    "    fileDf = pd.read_csv(csvFilePath,header=0, names=['chr','star','end','id',dataColName])\n",
    "    totalReads = fileDf[dataColName].sum()\n",
    "\n",
    "    scalingFactor = totalReads/100000\n",
    "\n",
    "    fileDf[dataColName] = fileDf[dataColName].apply(lambda x: x/scalingFactor)\n",
    "\n",
    "    return fileDf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "761dd5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce new function https://stackoverflow.com/questions/44327999/python-pandas-merge-multiple-dataframes\n",
    "\n",
    "input_narrowpeaks_folders = ['data_loops_fl_1','data_loops_fl_2']\n",
    "input_narrowpeaks_subfolders = ['MYC2FL/loopPIF4','MYC2FL/loopPIF5','MYC2FL/WT','Input/Input']\n",
    "allNormalizedreplicates = []\n",
    "\n",
    "# parse the experiments file to get the id of each exeriment and the path to that experiment\n",
    "for experiment in input_narrowpeaks_subfolders:\n",
    "    listofdfs = []\n",
    "    datacolnames = []\n",
    "    for parent_folder in input_narrowpeaks_folders:\n",
    "\n",
    "        workingFolder = os.path.join(basePathDataFolder,parent_folder,experiment)\n",
    "        datacolname = '{}{}'.format(experiment.replace('/','_'),parent_folder)\n",
    "        listofdfs.append(generateDfandNormaliceDataTPMs(workingFolder,datacolname))\n",
    "        datacolnames.append(datacolname)\n",
    "#             los valores que no estan en una de las replicas los completo con un 0\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['chr','star','end','id'],\n",
    "                                                    how='outer'), listofdfs).fillna(0)\n",
    "    #                 print(df_merged)\n",
    "    mean_col_name = '{}'.format(experiment.replace('/','_'))\n",
    "    df_merged[mean_col_name] = df_merged[datacolnames].mean(axis=1)\n",
    "    df_merged = df_merged.drop(columns=datacolnames)\n",
    "    \n",
    "    allNormalizedreplicates.append(df_merged)\n",
    "\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['chr','star','end','id'],\n",
    "                                                    how='outer'), allNormalizedreplicates).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0bf866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('/home/joaquin/projects/methylation/data/loops_subproject_jose/resultado_loops_fl.tsv', index=False,sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "methylation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b311b5e2c1aaa04d48066871c65b4e8ce80fb760bb38a0437727056581097150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
